# **Sistema de Respaldo para Soluci√≥n Productiva Power Platform + SharePoint**

  **Autor:** Milan Kurte
  **Fecha:** Diciembre 2025
  **Presupuesto Azure:** USD $60 por 30 d√≠as
  **RPO:** 24 horas
  **RTO:** 6 horas

---

# **1. Introducci√≥n**

  El objetivo de esta solucion es dise√±ar e implementar un **sistema de respaldo seguro, econ√≥mico y funcional** para una soluci√≥n productiva compuesta por:

* **Power Platform**: aplicaciones, soluciones, flujos y artefactos productivos.
* **Microsoft SharePoint Online**: repositorio de documentaci√≥n del cliente.

  El sistema debe permitir una recuperaci√≥n confiable ante p√©rdidas de datos, fallas del tenant o corrupci√≥n de la soluci√≥n, cumpliendo con las restricciones de presupuesto.

---

# **2. Objetivos del sistema de respaldo**

  Los objetivos principales son:

1. Proteger la soluci√≥n productiva de Power Platform y su documentaci√≥n en SharePoint mediante respaldos regulares.
2. Cumplir con los tiempos de continuidad acordados:

   * RPO (Recovery Point Objective): 24 horas ‚Üí m√°ximo un d√≠a de p√©rdida de informaci√≥n.
   * RTO (Recovery Time Objective): 6 horas ‚Üí m√°ximo seis horas para recuperar el servicio.
3. Dise√±ar una soluci√≥n simple, econ√≥mica y segura, basada en herramientas nativas de Azure y Microsoft 365.
4. Incluir un plan de contingencia que contemple una copia f√≠sica semanal en un medio on-premise (HDD).

---

# **3. Alcance del Sistema de Respaldo**

## **3.1 Componentes de Power Platform a respaldar**

* Exportaci√≥n de la **soluci√≥n productiva**.
* Copia de seguridad de **aplicaciones Canvas/Model-Driven** incluidas en la soluci√≥n.
* Exportaci√≥n de **flujos de Power Automate** asociados.
* Exportaci√≥n de **tablas cr√≠ticas de Dataverse**.
* Metadatos relevantes: configuraciones, conectores, par√°metros de ambiente.

## **3.2 Componentes de SharePoint a respaldar**

* Biblioteca principal que contiene documentaci√≥n del cliente.
* Archivos y carpetas en su estructura actual.
* Opcional: metadata b√°sica (creaci√≥n, modificaci√≥n).

## **3.3 No incluido**

* Exchange, OneDrive y Teams no est√°n involucrados en la soluci√≥n.
* No se usar√°n herramientas de terceros como Veeam debido a costo, complejidad y falta de compatibilidad con Power Platform.

---

# **4. Requisitos y restricciones**

  El dise√±o del sistema de respaldo se ha realizado considerando los siguientes requisitos y restricciones:

* Uso exclusivo de Azure y Microsoft 365 como plataformas tecnol√≥gicas.
* Existencia de l√≠mites de uso y llamadas a APIs en Power Platform, Dataverse y Microsoft Graph, lo que obliga a dise√±ar procesos moderados y eficientes (evitar respaldos demasiado frecuentes o masivos).
* Necesidad de controlar el acceso a los respaldos mediante un sistema de identidades y permisos (Identity and Access Management) utilizando Microsoft Entra ID y roles en Azure.

# **5. Requerimientos Funcionales y No Funcionales**

## **5.1 Funcionales**

* Respaldar diariamente Power Platform y SharePoint.
* Almacenar los respaldos de forma segura en Azure.
* Permitir restaurar la soluci√≥n en menos de 6 horas (RTO).
* Garantizar p√©rdida m√°xima de 24 horas de datos (RPO).

## **5.2 No Funcionales**

* Usar servicios Azure
* Minimizar uso de recursos costosos como m√°quinas virtuales.
* Controlar accesos usando mecanismos IAM de Azure (Entra ID + RBAC).
* Mantener evidencia de ejecuci√≥n mediante logs.

---

# **6. Gesti√≥n de costos y l√≠mites de APIs**

El dise√±o busca:

* Utilizar servicios ligeros y nativos de Azure, evitando m√°quinas virtuales o software de terceros de alto costo.
* Elegir un nivel de almacenamiento apropiado (ej. ‚ÄúCool‚Äù) para reducir el costo por gigabyte almacenado.
* Dise√±ar una frecuencia de respaldo moderada (una vez al d√≠a) que:

  * Cumple el RPO de 24 horas.
  * Evita un uso excesivo de las APIs de Power Platform y Microsoft Graph, que tienen l√≠mites diarios y pueden aplicar restricciones si se abusa de ellas.

Con esto se busca un equilibrio entre:

* Protecci√≥n de la informaci√≥n (copias diarias).
* Uso responsable de APIs (sin generar miles de llamadas por d√≠a).
* Control de costos (muy por debajo del l√≠mite de 60 USD).

---

# **7. Arquitectura Propuesta del Sistema de Respaldo**

  La soluci√≥n fue dise√±ada bajo los principios de simplicidad, econom√≠a y seguridad.

## **7.1 Componentes**

### **A. Microsoft Entra ID (Azure AD)**

* Identity & Access Management del sistema.
* Creaci√≥n de una **Identidad de Servicio** o **Managed Identity** asociada al Automation Account.
* Asignaci√≥n de roles RBAC m√≠nimos necesarios:

  * **Power Platform Admin / Environment Maker** (solo en ambiente a respaldar).
  * **SharePoint Administrator** (solo en sitio espec√≠fico).
  * **Storage Blob Data Contributor** (solo para contenedor de backups).

### **B. Azure Automation Account**

* Orquestador centralizado del proceso de respaldo.
* Contendr√° **tres Runbooks (PowerShell)**:

  * `Backup-PowerPlatform.ps1` - Ejecuta en la nube (diario, 02:00 AM)
  * `Backup-SharePoint.ps1` - Ejecuta en la nube (diario, 03:00AM)
  * `Backup-FisicoSemanal.ps1` - Ejecuta en Hybrid Worker (semanal, viernes 02:00)
* Programaci√≥n autom√°tica mediante schedules.
* Uso de **Managed Identity** para respaldos en la nube.
* Uso de **SAS Token de solo lectura** para respaldo f√≠sico.

### **C. Azure Storage Account**

* Tipo: **StorageV2 Standard LRS**
* Access Tier: **Cool**.
* Contenedores:

  * `pp-backup` ‚Üí Soluciones, apps, Dataverse.
  * `sp-backup` ‚Üí Bibliotecas/archivos SharePoint.
  * `logs` ‚Üí Registros de ejecuci√≥n y auditor√≠a.

### **D. Hybrid Runbook Worker (PC On-Premise)**

* **Funci√≥n**: Ejecutar runbook semanal localmente para copia f√≠sica.
* **Conectividad**: Comunicaci√≥n segura HTTPS con Azure Automation.
* **Requisitos**:
  * Agente Hybrid Worker instalado y registrado.
  * AzCopy disponible en el sistema.
  * Disco duro local con espacio suficiente (>100 GB).
  * PC encendido en ventana de ejecuci√≥n (viernes 20:00-21:00).
* **Seguridad**: Solo requiere SAS token de lectura (sin credenciales privilegiadas).

### **E. HDD F√≠sico**

* **Automatizaci√≥n**: Copia semanal v√≠a Hybrid Runbook Worker + AzCopy.
* **Rol**: Plan de contingencia ante escenarios extremos (ca√≠da de tenant, indisponibilidad Azure).

---

# **8. Flujo de Respaldo**

## **8.1 Arquitectura de Ejecuci√≥n**

El sistema de respaldo funciona mediante dos **Runbooks de Azure Automation** que se ejecutan diariamente a las **02:00 AM UTC-0 y 03:00 AM UTC-0** (horario de menor actividad del usuario).

### **Componentes t√©cnicos utilizados:**

| Componente               | Tecnolog√≠a                                   | Justificaci√≥n                                                   |
| ------------------------ | --------------------------------------------- | ---------------------------------------------------------------- |
| **Orquestador**    | Azure Automation Runbooks (PowerShell 7.2)    | Nativo, econ√≥mico, soporta Managed Identity                     |
| **Autenticaci√≥n** | Managed Identity del Automation Account       | Evita credenciales hardcodeadas, principio de m√≠nimo privilegio |
| **Power Platform** | Microsoft.PowerApps.Administration.PowerShell | M√≥dulo oficial, no requiere CLI, maneja APIs correctamente      |
| **SharePoint**     | PnP.PowerShell                                | Nativo, optimizado, soporta paginaci√≥n autom√°tica              |
| **Almacenamiento** | Azure Storage Account (Cool tier, LRS)        | Bajo costo, alta durabilidad                                     |
| **Logs**           | Azure Storage Blobs (JSON estructurado)       | Trazabilidad, bajo costo, f√°cil consulta                        |

---

## **8.2 Flujo Detallado: Power Platform Backup**

### **Diagrama de Secuencia**

![Texto alternativo de la imagen](images\DiagramaSecuenciaPP.png)

### **Paso 1: Inicializaci√≥n y Autenticaci√≥n**

```powershell
# Autenticaci√≥n mediante Managed Identity
Connect-AzAccount -Identity

# Importar m√≥dulos necesarios
Import-Module Microsoft.PowerApps.Administration.PowerShell
Import-Module Az.Storage

# Variables de configuraci√≥n
$environmentName = "prod-powerplatform-env"
$storageAccountName = "backupstoragenfdata"
$containerName = "pp-backup"
$date = Get-Date -Format "yyyyMMdd_HHmmss"
$tempPath = "$env:TEMP\PPBackup_$date"
```

### **Paso 2: Exportaci√≥n de Soluci√≥n Power Platform**

```powershell
# Obtener informaci√≥n del ambiente
$env = Get-AdminPowerAppEnvironment -EnvironmentName $environmentName

# Exportar soluci√≥n usando API REST (m√°s confiable que CLI)
$solutionName = "ClientProductionSolution"
$exportUrl = "https://$($env.EnvironmentName).api.crm.dynamics.com/api/data/v9.2/ExportSolution"

$body = @{
    SolutionName = $solutionName
    Managed = $false
    ExportAutoNumberingSettings = $true
    ExportCalendarSettings = $true
    ExportCustomizationSettings = $true
    ExportEmailTrackingSettings = $true
} | ConvertTo-Json

# Ejecutar exportaci√≥n con retry logic
$maxRetries = 3
$retryDelay = 5
$attempt = 0
$success = $false

while (-not $success -and $attempt -lt $maxRetries) {
    try {
        $response = Invoke-RestMethod -Uri $exportUrl -Method Post -Body $body `
            -ContentType "application/json" -Headers @{
                Authorization = "Bearer $(Get-AzAccessToken -ResourceUrl 'https://org.crm.dynamics.com')"
            }
  
        # Guardar ZIP de soluci√≥n
        $solutionPath = "$tempPath\$solutionName`_$date.zip"
        [System.IO.File]::WriteAllBytes($solutionPath, $response.ExportSolutionFile)
  
        $success = $true
        Write-Output "‚úì Soluci√≥n exportada: $solutionPath"
  
    } catch {
        $attempt++
        if ($_.Exception.Response.StatusCode -eq 429) {
            # Throttling detectado - esperar con backoff exponencial
            $waitTime = $retryDelay * [Math]::Pow(2, $attempt)
            Write-Warning "‚ö† Throttling detectado. Esperando $waitTime segundos..."
            Start-Sleep -Seconds $waitTime
        } else {
            throw $_
        }
    }
}
```

### **Paso 3: Exportaci√≥n de Tablas Cr√≠ticas de Dataverse**

```powershell
# Definir tablas cr√≠ticas a respaldar
$criticalTables = @(
    "cr_customerdata",
    "cr_transactions",
    "cr_configurations"
)

foreach ($tableName in $criticalTables) {
    try {
        # Query con paginaci√≥n autom√°tica
        $dataUrl = "https://$($env.EnvironmentName).api.crm.dynamics.com/api/data/v9.2/$tableName"
  
        $allRecords = @()
        $nextLink = $dataUrl
  
        while ($nextLink) {
            $response = Invoke-RestMethod -Uri $nextLink -Method Get -Headers @{
                Authorization = "Bearer $(Get-AzAccessToken -ResourceUrl 'https://org.crm.dynamics.com')"
                Prefer = "odata.maxpagesize=5000"
            }
  
            $allRecords += $response.value
            $nextLink = $response.'@odata.nextLink'
  
            # Pausa para evitar throttling
            Start-Sleep -Milliseconds 200
        }
  
        # Guardar en JSON
        $jsonPath = "$tempPath\$tableName`_$date.json"
        $allRecords | ConvertTo-Json -Depth 10 | Out-File -FilePath $jsonPath -Encoding UTF8
  
        Write-Output "‚úì Tabla exportada: $tableName ($($allRecords.Count) registros)"
  
    } catch {
        Write-Error "‚úó Error exportando tabla $tableName : $_"
        # Continuar con siguiente tabla
    }
}
```

### **Paso 4: Subida a Azure Storage**

```powershell
# Obtener contexto de Storage Account
$ctx = New-AzStorageContext -StorageAccountName $storageAccountName -UseConnectedAccount

# Comprimir todos los archivos
$zipFileName = "PowerPlatform_Backup_$date.zip"
$zipPath = "$env:TEMP\$zipFileName"
Compress-Archive -Path "$tempPath\*" -DestinationPath $zipPath -CompressionLevel Optimal

# Subir a blob storage
Set-AzStorageBlobContent -File $zipPath -Container $containerName -Blob $zipFileName `
    -Context $ctx -Force

Write-Output "‚úì Backup subido a Storage Account: $zipFileName"

# Limpiar archivos temporales
Remove-Item -Path $tempPath -Recurse -Force
Remove-Item -Path $zipPath -Force
```

### **Paso 5: Registro de Ejecuci√≥n**

```powershell
# Crear log estructurado
$logEntry = @{
    timestamp = (Get-Date).ToUniversalTime().ToString("o")
    service = "PowerPlatform"
    status = "success"
    environment = $environmentName
    solutionExported = $solutionName
    tablesExported = $criticalTables.Count
    backupFileName = $zipFileName
    backupSizeMB = [Math]::Round((Get-Item $zipPath).Length / 1MB, 2)
    durationSeconds = $executionDuration
    errors = @()
} | ConvertTo-Json

# Guardar log en contenedor logs
$logFileName = "log_PP_$date.json"
$logPath = "$env:TEMP\$logFileName"
$logEntry | Out-File -FilePath $logPath -Encoding UTF8

Set-AzStorageBlobContent -File $logPath -Container "logs" -Blob "powerplatform/$logFileName" `
    -Context $ctx -Force

Remove-Item -Path $logPath -Force
```

---

## **8.3 Flujo Detallado: SharePoint Backup**

### **Diagrama de Secuencia**

![Texto alternativo de la imagen](images\DiagramaSecuenciaSP.png)

### **Paso 1: Conexi√≥n a SharePoint**

```powershell
# Importar m√≥dulo PnP
Import-Module PnP.PowerShell

# Variables
$siteUrl = "https://nofrontiersdata.sharepoint.com/sites/ClientDocs"
$libraryName = "Documentos Compartidos"
$date = Get-Date -Format "yyyyMMdd_HHmmss"
$tempPath = "$env:TEMP\SPBackup_$date"
New-Item -ItemType Directory -Path $tempPath -Force | Out-Null

# Conexi√≥n con Managed Identity
Connect-PnPOnline -Url $siteUrl -ManagedIdentity
```

### **Paso 2: Descarga de Biblioteca con Paginaci√≥n**

```powershell
# Obtener todos los archivos con paginaci√≥n autom√°tica
$allItems = Get-PnPListItem -List $libraryName -PageSize 2000 -Fields "FileLeafRef","FileRef","File_x0020_Size","Modified"

Write-Output "üìÅ Total de items encontrados: $($allItems.Count)"

$downloadedFiles = 0
$totalSize = 0

foreach ($item in $allItems) {
    try {
        # Solo procesar archivos (no carpetas)
        if ($item.FileSystemObjectType -eq "File") {
            $fileUrl = $item.FieldValues.FileRef
            $fileName = $item.FieldValues.FileLeafRef
  
            # Recrear estructura de carpetas
            $relativePath = $fileUrl.Replace($libraryName, "").TrimStart('/')
            $localPath = Join-Path $tempPath $relativePath
            $localDir = Split-Path $localPath -Parent
  
            if (-not (Test-Path $localDir)) {
                New-Item -ItemType Directory -Path $localDir -Force | Out-Null
            }
  
            # Descargar archivo
            Get-PnPFile -Url $fileUrl -Path $localDir -FileName $fileName -AsFile -Force
  
            $downloadedFiles++
            $totalSize += $item.FieldValues.File_x0020_Size
  
            # Pausa para evitar throttling (cada 100 archivos)
            if ($downloadedFiles % 100 -eq 0) {
                Write-Output "  Descargados: $downloadedFiles archivos..."
                Start-Sleep -Milliseconds 500
            }
        }
    } catch {
        Write-Warning "‚ö† Error descargando $($item.FieldValues.FileLeafRef): $_"
        # Continuar con siguiente archivo
    }
}

Write-Output "‚úì Descarga completada: $downloadedFiles archivos ($([Math]::Round($totalSize/1MB, 2)) MB)"
```

### **Paso 3: Compresi√≥n y Subida**

```powershell
# Comprimir biblioteca completa
$zipFileName = "SharePoint_Backup_$date.zip"
$zipPath = "$env:TEMP\$zipFileName"

Compress-Archive -Path "$tempPath\*" -DestinationPath $zipPath -CompressionLevel Optimal

# Subir a Storage Account
$ctx = New-AzStorageContext -StorageAccountName $storageAccountName -UseConnectedAccount

Set-AzStorageBlobContent -File $zipPath -Container "sp-backup" -Blob $zipFileName `
    -Context $ctx -Force

Write-Output "‚úì Backup SharePoint subido: $zipFileName"

# Limpiar temporales
Remove-Item -Path $tempPath -Recurse -Force
Remove-Item -Path $zipPath -Force
```

### **Paso 4: Log de Ejecuci√≥n**

```powershell
$logEntry = @{
    timestamp = (Get-Date).ToUniversalTime().ToString("o")
    service = "SharePoint"
    status = "success"
    siteUrl = $siteUrl
    library = $libraryName
    filesBackedUp = $downloadedFiles
    backupSizeMB = [Math]::Round((Get-Item $zipPath).Length / 1MB, 2)
    durationSeconds = $executionDuration
} | ConvertTo-Json

$logFileName = "log_SP_$date.json"
$logPath = "$env:TEMP\$logFileName"
$logEntry | Out-File -FilePath $logPath -Encoding UTF8

Set-AzStorageBlobContent -File $logPath -Container "logs" -Blob "sharepoint/$logFileName" `
    -Context $ctx -Force

Remove-Item -Path $logPath -Force
```

---

## **8.4 Flujo: Respaldo F√≠sico Semanal con Hybrid Runbook Worker**

### **8.4.1 Concepto y Arquitectura**

A diferencia de los respaldos diarios que se ejecutan completamente en la nube, el respaldo semanal utiliza un **Hybrid Runbook Worker** para automatizar la copia desde Azure Storage hacia un disco duro f√≠sico on-premise.

**Componentes involucrados:**

![Texto alternativo de la imagen](images\FlujoRespaldoFisico.png)

### **8.4.2 Flujo L√≥gico de Ejecuci√≥n**

**Paso 1: Programaci√≥n Semanal**

- Se configura un **schedule semanal** en Azure Automation (ejemplo: domingo 02:00 AM)
- El schedule est√° vinculado al runbook `Backup-FisicoSemanal.ps1`
- La programaci√≥n se gestiona centralmente desde Azure Portal

**Paso 2: Despacho del Job**

- Cuando llega la hora programada, Azure Automation activa el runbook
- El job **NO se ejecuta en la nube de Azure**
- El job se env√≠a al **Hybrid Runbook Worker** registrado en el PC on-premise
- La comunicaci√≥n se realiza de forma segura via HTTPS

**Paso 3: Ejecuci√≥n Local del Runbook**

El script ejecuta en el PC on-premise con la siguiente l√≥gica:

```powershell
# Runbook: Backup-FisicoSemanal.ps1
# Ejecuta en Hybrid Runbook Worker (PC on-premise)

# Variables de configuraci√≥n
$storageAccount = "backupstoragenfdata"
$sasToken = Get-AutomationVariable -Name "SAS-Token-ReadOnly-Weekly"  # Almacenado como variable cifrada
$hddPath = "E:\Backups"
$date = Get-Date -Format "yyyyMMdd_HHmmss"
$logFile = "$hddPath\backup_fisico_$date.log"

# Iniciar logging
"[$(Get-Date)] Inicio de respaldo f√≠sico semanal" | Out-File $logFile

try {
    # Sincronizar contenedor pp-backup
    Write-Output "Sincronizando Power Platform backups..."
    & azcopy sync "https://$storageAccount.blob.core.windows.net/pp-backup$sasToken" `
        "$hddPath\pp-backup" --recursive --delete-destination=false --log-level=INFO
  
    "[$(Get-Date)] ‚úì Power Platform sincronizado" | Out-File $logFile -Append
  
    # Sincronizar contenedor sp-backup
    Write-Output "Sincronizando SharePoint backups..."
    & azcopy sync "https://$storageAccount.blob.core.windows.net/sp-backup$sasToken" `
        "$hddPath\sp-backup" --recursive --delete-destination=false --log-level=INFO
  
    "[$(Get-Date)] ‚úì SharePoint sincronizado" | Out-File $logFile -Append
  
    # Sincronizar logs (opcional)
    Write-Output "Sincronizando logs de auditor√≠a..."
    & azcopy sync "https://$storageAccount.blob.core.windows.net/logs$sasToken" `
        "$hddPath\logs" --recursive --delete-destination=false --log-level=INFO
  
    "[$(Get-Date)] ‚úì Logs sincronizados" | Out-File $logFile -Append
  
    # Calcular tama√±o total respaldado
    $totalSize = (Get-ChildItem $hddPath -Recurse | Measure-Object Length -Sum).Sum / 1GB
    $message = "‚úì Backup semanal completado. Tama√±o total: $([Math]::Round($totalSize, 2)) GB"
  
    Write-Output $message
    "[$(Get-Date)] $message" | Out-File $logFile -Append
  
    # Retornar resultado exitoso
    return @{
        Status = "Success"
        TotalSizeGB = [Math]::Round($totalSize, 2)
        Timestamp = $date
        LogFile = $logFile
    }
  
} catch {
    $errorMessage = "‚úó Error en respaldo f√≠sico: $($_.Exception.Message)"
    Write-Error $errorMessage
    "[$(Get-Date)] $errorMessage" | Out-File $logFile -Append
  
    throw $_
}
```

**Paso 4: Sincronizaci√≥n con AzCopy**

- AzCopy se invoca con comando `sync` (no `copy`)
- `sync` solo transfiere archivos nuevos o modificados (eficiente)
- Par√°metro `--delete-destination=false` preserva archivos locales antiguos
- El acceso usa **SAS token de solo lectura** con:
  - Alcance limitado a contenedores espec√≠ficos (`pp-backup`, `sp-backup`, `logs`)
  - Fecha de expiraci√≥n definida (renovar mensualmente)
  - Permisos m√≠nimos: solo lectura (no escritura, no eliminaci√≥n)

**Paso 5: Registro y Monitoreo**

- El resultado se registra como **job en Azure Automation**
- M√©tricas disponibles: duraci√≥n, estado (√©xito/error), output
- Log local adicional en el HDD: `backup_fisico_YYYYMMDD.log`
- Alertas autom√°ticas en caso de fallo

### **8.4.3 Configuraci√≥n del SAS Token**

```powershell
# Generaci√≥n de SAS Token (ejecutar una vez al mes)
# Desde Azure Portal o PowerShell

$context = New-AzStorageContext -StorageAccountName "backupstoragenfdata" -UseConnectedAccount

# SAS para contenedor pp-backup (solo lectura, 30 d√≠as)
$sasPP = New-AzStorageContainerSASToken -Context $context `
    -Name "pp-backup" `
    -Permission r `
    -ExpiryTime (Get-Date).AddDays(30)

# SAS para contenedor sp-backup
$sasSP = New-AzStorageContainerSASToken -Context $context `
    -Name "sp-backup" `
    -Permission r `
    -ExpiryTime (Get-Date).AddDays(30)

# Guardar como variable cifrada en Automation Account
Set-AzAutomationVariable -AutomationAccountName "aa-backups" `
    -Name "SAS-Token-ReadOnly-Weekly" `
    -Value $sasPP `
    -Encrypted $true `
    -ResourceGroupName "rg-backups"
```

### **8.4.4 Rol en el Plan de Contingencia**

**Importancia estrat√©gica:**

- **No altera RPO/RTO operativo** - Los backups diarios en Azure siguen siendo la fuente primaria
- **Defensa contra escenarios extremos**:

  - Ca√≠da prolongada del tenant Microsoft 365
  - Problemas graves de seguridad (ransomware en la nube)
  - Indisponibilidad de Azure Storage
  - Corrupci√≥n masiva de datos en la nube
- **Independencia tecnol√≥gica** - Copia f√≠sica accesible sin dependencia de servicios cloud
- **Cumplimiento normativo** - Algunas regulaciones requieren copias off-cloud

**Escenario de uso:**

Si Azure/M365 est√° completamente inaccesible, el equipo puede:

1. Acceder al HDD f√≠sico sin depender de conectividad cloud
2. Restaurar en ambiente alternativo (tenant de desarrollo, nube privada)
3. Mantener operaciones cr√≠ticas mientras se resuelve el incidente mayor

### **8.4.5 Requisitos y Consideraciones Operativas**

**Requisitos del PC On-Premise:**

| Requisito                   | Detalle                                                                     |
| --------------------------- | --------------------------------------------------------------------------- |
| **Conectividad**      | Acceso a Internet para comunicarse con Azure Automation y Storage           |
| **Disponibilidad**    | Debe estar encendido en la ventana horaria del backup (Domingo 02:00-03:00) |
| **Almacenamiento**    | Espacio suficiente en HDD                                                   |
| **Software**          | AzCopy instalado y accesible en PATH del sistema                            |
| **Agente**            | Hybrid Runbook Worker agent instalado y registrado                          |
| **Sistema Operativo** | Windows 10/11 Pro o Windows Server 2016+                                    |
| **Permisos locales**  | Cuenta con permisos de escritura en E:\Backups\                             |

**Instalaci√≥n del Hybrid Runbook Worker:**

El equipo on-premise se registra en Azure como Hybrid Runbook Worker siguiendo estos pasos generales:

1. **Instalaci√≥n del agente**:

   - Desde Azure Portal > Automation Account > Hybrid Worker Groups
   - Descargar e instalar el agente en el PC
   - Registrar el PC con el Workspace ID del Automation Account
2. **Configuraci√≥n del grupo**:

   - Crear grupo "HybridWorkers-Backup"
   - Asignar el PC al grupo
   - Configurar el runbook `Backup-FisicoSemanal.ps1` para ejecutarse en este grupo (no en Azure)
3. **Verificaci√≥n**:

   - Ejecutar prueba manual del runbook
   - Validar que el job se ejecuta en el PC on-premise
   - Confirmar que AzCopy descarga archivos correctamente

Esto permite que los runbooks definidos en el Automation Account se ejecuten localmente, manteniendo la gesti√≥n, programaci√≥n y logs centralizados en Azure.

**Plan de Contingencia si el PC est√° Apagado:**

| Situaci√≥n                                 | Acci√≥n                                                                           |
| ------------------------------------------ | --------------------------------------------------------------------------------- |
| **PC apagado en horario programado** | Alerta autom√°tica v√≠a Azure Monitor al d√≠a siguiente                           |
| **Respuesta**                        | Administrador enciende PC y ejecuta manualmente el runbook                        |
| **Prevenci√≥n**                      | Configurar encendido autom√°tico (WoL) o programar en horario laboral alternativo |

### **8.4.6 Custodia y Seguridad del HDD**

| Aspecto                     | Detalle                                               |
| --------------------------- | ----------------------------------------------------- |
| **Frecuencia**        | Semanal (Domingo 02:00 AM)                            |
| **Automatizaci√≥n**   | Completamente automatizada v√≠a Hybrid Runbook Worker |
| **Seguridad f√≠sica** | PC en sala con acceso controlado                      |
| **Cifrado**           | BitLocker habilitado en volumen E:\                   |
| **Monitoreo**         | Logs en Azure Automation + archivo local              |

---

## **8.5 Gesti√≥n de Retenci√≥n y Lifecycle**

### **Pol√≠tica de Retenci√≥n Implementada**

```json
{
  "rules": [
    {
      "name": "DeleteOldBackups",
      "enabled": true,
      "type": "Lifecycle",
      "definition": {
        "filters": {
          "blobTypes": ["blockBlob"],
          "prefixMatch": ["pp-backup/", "sp-backup/"]
        },
        "actions": {
          "baseBlob": {
            "tierToCool": {
              "daysAfterModificationGreaterThan": 7
            },
            "delete": {
              "daysAfterModificationGreaterThan": 30
            }
          }
        }
      }
    }
  ]
}
```

### **Estrategia:**

- **D√≠as 0-7**: Backups en tier **Hot** (acceso r√°pido para RTO)
- **D√≠as 8-30**: Movidos a tier **Cool** (ahorro de costos)
- **D√≠a 31+**: Eliminaci√≥n autom√°tica (mantiene 30 d√≠as de historia)

---

## **8.6 Manejo de Errores y Reintentos**

### **Escenarios Contemplados**

| Error                    | C√≥digo HTTP             | Estrategia                           |
| ------------------------ | ------------------------ | ------------------------------------ |
| **Throttling**     | 429 Too Many Requests    | Exponential backoff (5s, 10s, 20s)   |
| **Timeout**        | 408 Request Timeout      | Reintento inmediato (1 vez)          |
| **Autenticaci√≥n** | 401 Unauthorized         | Renovar token, reintentar            |
| **Storage lleno**  | 507 Insufficient Storage | Alertar administrador, no reintentar |
| **Red inestable**  | NetworkError             | 3 reintentos con 5s de espera        |

### **Implementaci√≥n en Runbooks**

```powershell
function Invoke-WithRetry {
    param(
        [scriptblock]$ScriptBlock,
        [int]$MaxRetries = 3,
        [int]$BaseDelay = 5
    )
  
    $attempt = 0
    while ($attempt -lt $MaxRetries) {
        try {
            return & $ScriptBlock
        } catch {
            $attempt++
            $statusCode = $_.Exception.Response.StatusCode.Value__
  
            if ($statusCode -eq 429 -and $attempt -lt $MaxRetries) {
                $delay = $BaseDelay * [Math]::Pow(2, $attempt)
                Write-Warning "Throttling - Esperando $delay segundos (intento $attempt/$MaxRetries)"
                Start-Sleep -Seconds $delay
            } else {
                throw $_
            }
        }
    }
}
```

---

## **8.7 Monitoreo y Alertas**

### **Alertas Configuradas (Azure Monitor)**

```powershell
# Alerta si el runbook falla
New-AzMetricAlertRuleV2 -Name "BackupFailureAlert" `
    -ResourceGroupName "rg-backups" `
    -TargetResourceId "/subscriptions/.../automationAccounts/aa-backups" `
    -Condition "Whenever the total job failures is greater than 0" `
    -WindowSize 01:00:00 `
    -Frequency 00:05:00 `
    -Severity 2 `
    -ActionGroupId "/subscriptions/.../actionGroups/ag-backup-alerts"
```

---

# **9. IAM ‚Äì Gesti√≥n de Identidades y Accesos**

  La implementaci√≥n de Identity and Access Management (IAM) en esta soluci√≥n utiliza **Microsoft Entra ID** (Azure AD)  para garantizar el principio de m√≠nimo privilegio.

### **9.1 Microsoft Entra ID**

* Gesti√≥n centralizada de identidades (usuarios, grupos, aplicaciones, service principals).
* Emisi√≥n de tokens de autenticaci√≥n para servicios automatizados.
* Control de Managed Identities para recursos Azure.

### **9.2 Azure RBAC - Roles y Permisos**

  **Matriz de permisos por componente:**

| Recurso                               | Rol                           | Asignado a                                    | Justificaci√≥n                                                           |
| ------------------------------------- | ----------------------------- | --------------------------------------------- | ------------------------------------------------------------------------ |
| **Storage Account (escritura)** | Storage Blob Data Contributor | Managed Identity del Automation Account       | Los runbooks diarios debenescribir respaldos en contenedores             |
| **Storage Account (lectura)**   | SAS Token de solo lectura     | Hybrid Runbook Worker (v√≠a variable cifrada) | El runbook semanal sololee para copiar al HDD local                      |
| **Automation Account**          | Contributor                   | Administrador t√©cnico                        | Gesti√≥n de runbooks, schedules y variables                              |
| **Power Platform Environment**  | Environment Admin o Maker     | Managed Identity del Automation Account       | Exportar soluciones y acceder a Dataverse                                |
| **SharePoint Site**             | Site Collection Administrator | Managed Identity del Automation Account       | Descargar bibliotecas de documentos                                      |
| **Hybrid Worker Group**         | (Sin permisos adicionales)    | PC on-premise                                 | Solo ejecuta scripts localmente, no accede directamente a recursos Azure |

# **10. Cadencia y Justificaci√≥n (RPO/RTO)**

## **10.1 Cadencia diaria (02:00 AM)**

* Permite cumplir **RPO = 24 horas**.
* Evita alto uso de APIs durante horarios laborales.
* Minimiza costos (menos llamadas API, menos cargas).

## **10.3 RTO = 6 horas**

  Factores que permiten cumplirlo:

* Restauraci√≥n de soluci√≥n Power Apps toma minutos.
* Restauraci√≥n de SharePoint es directa (repositorio de archivos).
* Scripts de recuperaci√≥n documentados.
* Todo est√° en Storage Account de r√°pido acceso.

---

# **11. Plan de Contingencia**

## **Escenario 1: Fallo parcial (p√©rdida de una app o flujo)**

1. Descargar √∫ltima copia desde `pp-backup`.
2. Importar soluci√≥n en Power Platform.
3. Validar flujos.
4. Reabrir ambiente.

  Duraci√≥n estimada: 1‚Äì2 horas.

---

## **Escenario 2: P√©rdida completa del SharePoint**

1. Descargar √∫ltimo ZIP de `sp-backup`.
2. Usar PnP.PowerShell para restaurar carpeta o biblioteca.
3. Reindexaci√≥n autom√°tica de SharePoint.

  Duraci√≥n: 2‚Äì4 horas.

---

## **Escenario 3: Ca√≠da del tenant Azure/M365 (baja probabilidad)**

1. Usar copia semanal del HDD externo.
2. Restaurar en ambiente alternativo (dev o tenant temporal).
3. Comunicar a cliente.

  Duraci√≥n: < 6 horas (cumple RTO).

---

# **12. Costos Estimados**

| Servicio              | Detalle                               | Costo Mensual |
| --------------------- | ------------------------------------- | ------------- |
| Azure Storage Account | Cool tier, ~50GB, 30 d√≠as retenci√≥n | $1.50 - $3.00 |
| Azure Automation      | 3 runbooks, ~650 min/mes              | $1.30 - $2.00 |
| Hybrid Runbook Worker | Agente gratuito                       | $0.00         |
| Data Transfer Out     | ~50GB/mes descarga semanal            | $1.00 - $2.00 |
| Logs & Monitoring     | Application Insights b√°sico          | $0.50 - $1.00 |

**TOTAL:** $6.00 - $8.00/mes (7-13% del presupuesto de $60/mes)

**Muy por debajo del l√≠mite de USD $60**

---

# **13. Conclusiones**

  La arquitectura propuesta:

* **Cumple integralmente** con los requisitos t√©cnicos.
* Asegura restauraci√≥n dentro de los tiempos definidos (RTO 6h).
* Minimiza p√©rdida de datos gracias a respaldos diarios (RPO 24h).
* Usa servicios nativos de Azure y M365, manteniendo la complejidad muy baja.
* Incluye una estrategia racional de copia f√≠sica para contingencias extremas.

  En conclusi√≥n, este sistema es **simple, robusto, econ√≥mico y seguro**, ajust√°ndose plenamente al desaf√≠o asignado.
